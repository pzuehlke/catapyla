{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "\n",
    "Suppose that we have three-dimensional arrays $ \\mathbf u $ and $ \\mathbf v $\n",
    "and would like to take their inner (dot) product. Here's the most obvious way of doing\n",
    "this in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dimension = 3\n",
    "u = np.array([1, 2, 3])\n",
    "v = np.array([-1, 0, 1])\n",
    "\n",
    "product = 0\n",
    "for i in range(dimension):\n",
    "    product += u[i] * v[i]\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach's limitation is that it performs the required arithmetical\n",
    "operations *in sequence*. That is, we first compute the product $ 1 \\cdot (-1) $\n",
    "and add it to our cumulative total; then we add $ 2 \\cdot 0 $; and finally we add\n",
    "$ 3 \\cdot 1 $ to arrive at the result.\n",
    "\n",
    "We can speed up computations of this kind significantly by processing the\n",
    "entire arrays, or at least large chunks of the arrays, at once. This technique\n",
    "is called **vectorization**. It leverages the optimized implementations of vector and\n",
    "matrix operations provided by libraries such as NumPy, which make use of\n",
    "multi-core CPUs or even GPUs (Graphics Processing Units) to execute tasks *in\n",
    "parallel* whenever possible. \n",
    "\n",
    "The vectorized version of the previous example would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "u = np.array([1, 2, 3])\n",
    "v = np.array([-1, 0, 1])\n",
    "\n",
    "product = np.dot(u, v)  # Compute the dot product of u and v.\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version is certainly more concise and legible. However, because the vectors\n",
    "have only $ 3 $ dimensions, the performance boost is not noticeable. To better\n",
    "appreciate the power of vectorization, let's consider the task of computing\n",
    "the dot product of two vectors having $ 10 $ million dimensions. Here is the\n",
    "vectorized version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inner product is 2499843.426373514.\n",
      "Runtime for vectorized version: 4.890680313110352 ms.\n"
     ]
    }
   ],
   "source": [
    "import time  # Module that will allow us to time the computations\n",
    "\n",
    "# Generate two large vectors with random coordinates in [0, 1):\n",
    "dimension = 10**7\n",
    "u = np.random.rand(dimension)  \n",
    "v = np.random.rand(dimension)\n",
    "\n",
    "tic = time.time()\n",
    "prod = np.dot(u, v)\n",
    "toc = time.time()\n",
    "vect_runtime = toc - tic\n",
    "\n",
    "print(f\"The inner product is {prod}.\")\n",
    "print(f\"Runtime for vectorized version: {1000 * vect_runtime} ms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù The function `time.time()` used above returns a floating point number that\n",
    "represents the time in seconds since January 1st, 1970, 00:00:00 (UTC). The\n",
    "duration of the computation was measured by taking the time before (`tic`) and\n",
    "after (`toc`) it, and then taking the difference. \n",
    "\n",
    "Considering the dimension of the vectors, the computation was pretty fast. Let's\n",
    "now contrast the performance to that of its non-vectorized counterpart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inner product is 2499843.4263739116.\n",
      "Runtime for vectorized version: 1.4287347793579102 s.\n",
      "Or, in miliseconds: 1428.7347793579102\n"
     ]
    }
   ],
   "source": [
    "import time  # A module that will allow us to time the computations\n",
    "\n",
    "tic = time.time()\n",
    "prod = 0\n",
    "for i in range(dimension):\n",
    "    prod += u[i] * v[i]\n",
    "toc = time.time()\n",
    "non_vect_runtime = toc - tic\n",
    "print(f\"The inner product is {prod}.\")\n",
    "print(f\"Runtime for vectorized version: {non_vect_runtime} s.\")\n",
    "print(f\"Or, in miliseconds: {1000 * (non_vect_runtime)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù The slight discrepancy in the value of the dot product between the two\n",
    "versions arises because the non-vectorized method accumulates floating-point\n",
    "arithmetic errors more prominently than the vectorized operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Referring to the example above, compute the precise \n",
    "speedup factor relating the two implementations. Why does this value\n",
    "change everytime you compute it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This discussion shows that vectorization provides a simple way to improve the\n",
    "performance of our code by several orders of magnitude. This is especially\n",
    "crucial in machine learning and computer graphics. These fields frequently\n",
    "involve dealing with vast datasets and complex numerical computations. In such\n",
    "cases, code that does not make use of vectorization is simply not viable.\n",
    "\n",
    "To summarize: *When performing operations on arrays, avoid loops whenever\n",
    "possible; instead, use the built-in vectorized implementations provided by\n",
    "NumPy.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector- and matrix-valued functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate another aspect of vectorization, let $ \\mathbf u = (1, 2, 3) $ and\n",
    "suppose that we need to apply the exponential function to each of the\n",
    "coordinates of $ \\mathbf u $. That is, suppose that we wish to compute $ \\exp(u)\n",
    "= (e^1, e^2, e^3) $. We could simply use a for-loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.71828183  7.3890561  20.08553692]\n"
     ]
    }
   ],
   "source": [
    "u = np.array([1, 2, 3])\n",
    "v = np.zeros(3)  # will hold the result\n",
    "for i in range(3):\n",
    "    v[i] = np.exp(u[i])\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there is an alternative way that is both simpler and more efficient,\n",
    "namely, to use vectorization, in this case by leveraging to NumPy to apply the\n",
    "exponential to the vector $ u $ as a whole:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.71828183  7.3890561  20.08553692]\n"
     ]
    }
   ],
   "source": [
    "v = np.exp(u)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach also works with basic operations that are built into Python, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 9]\n"
     ]
    }
   ],
   "source": [
    "squared_u = u**2\n",
    "print(squared_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.5        0.33333333]\n"
     ]
    }
   ],
   "source": [
    "reciprocal_u = 1 / u\n",
    "print(reciprocal_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Similarly to what we did for the inner product, compare the difference in performance\n",
    "between the vectorized and non-vectorized approaches to computing $ e^u $, where $ u $ is a random\n",
    "vector having a large number of dimensions. What is the speedup factor, approximately?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Let $ u = (1, 2, 3) $. Compute:\n",
    "\n",
    "(a) $ \\log(u) $ (that is, the vector whose coordinates are the logarithms of the coordinates of $ u $). *Hint*: Use the `np.log` function.\n",
    "\n",
    "(b) $ \\vert{u}\\vert $ (that is, the vector whose coordinates are the absolute values of the coordinates of $ u $). *Hint:* Use the `np.abs` function.\n",
    "\n",
    "(c) $ \\max\\{u, 3\\} $. *Hint:* Use the `np.max` function.\n",
    "\n",
    "(d) $ \\sin\\big(\\tfrac{\\pi u}{2}\\big) $. *Hint:* Use the `np.sin` function.\n",
    "\n",
    "How did you interpret the vectors of items (c) and (d)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
